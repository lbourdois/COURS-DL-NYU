---
permalink: /
title: "Cours d'apprentissage profond de l'Université de New York"
excerpt: "Le cours de Yann LE CUN et Alfredo CANZIANI<br> traduit en français par Loïck BOURDOIS"
header:
   overlay_color: "#57068C"
layout: splash
---

<h1 style="text-align: center;">Avant-propos</h1>
<p> Ce cours porte sur les récentes techniques de représentation et d’apprentissage profond. Il se concentre sur l’apprentissage supervisé, non supervisé et autosupervisté, mais aussi sur les méthodes d’enchâssement, les réseaux convolutifs et récurrents.
 Il est illustré d’applications à la vision par ordinateur, la compréhension du langage naturel et la reconnaissance vocale.</p> 

<p> Pour suivre ce cours, il est fortement conseillé d’avoir des prérequis en algèbre et d’avoir déjà suivi un cours introductif d’apprentissage machine ou de science des données. Ces cours sont destinés à des personnes de niveau bac+4 ou bac+5.</p> 


<br><br><br>
<h1 style="text-align: center;", color="#57068C">Programme</h1>

<p>
Nous vous invitons à privilégier les vidéos de la [chaine YouTube](https://www.youtube.com/watch?v=0bMe_vCZo30&list=PLLHTzKZzVU9eaEyErdV26ikyolxOsz6mq) (contenu « officiel ») puisque le cours y est donné par le corps enseignant contrairement au site web où il s’agit des notes prises par les étudiants pendant le cours.
Le site web étant des résumés des vidéos, celles-ci comprennent donc généralement des informations supplémentaires par rapport au site. Comme par exemple :<br>
- des anecdotes sur les différents concepts abordés,<br>
- des blagues, <br>
- la répétition d’un même concept mais sous la forme de différentes formulations permettant ainsi généralement de comprendre une idée si une première formulation n’est pas saisie,<br> 
- les questions des étudiants qui peuvent être celles que vous ayez vous-même pendant le visionnage,<br>
Notez que si des concepts ne sont toujours pas compris à l’issue de la vidéo, vous avez la possibilité de poser une question en commentaire de la vidéo YouTube, ce que ne permet pas le site web.<br>
- les références des articles sur lesquels se basent le cours sont présentes sur les diapositives des vidéos alors qu’elles sont absentes du site. <br><br>
  
Le site web sert ainsi davantage de résumé des vidéos ou encore de base que vous pouvez réutiliser pour vos notes personnelles que vous prenez pendant le visionnage des vidéos. 
En cas de besoin vous pouvez facilement basculer du site à un moment d’une vidéo donnée en cliquant sur les titres des paragraphes des pages web.
</p>

* Semaine 1
* Titre vidéo CM
* Petite description
* Titre vidéo TD
* Petite description + Slides
* Notebook 


<table>
<!-- =============================== HEADER ================================ -->
  <thead>
    <tr>
      <th>Semaine</th>
      <th align="left">Format</th>
      <th align="left">Titre</th>
      <th align="left">Resources</th>
    </tr>
  </thead>
  <tbody>
<!-- =============================== SEMAINE 1 ================================ -->
    <tr>
      <td rowspan="3" align="center"><a href="{{site.baseurl}}/fr/week01/01">①</a></td>
      <td rowspan="2">Cours magistral</td>
      <td><a href="{{site.baseurl}}/fr/week01/01-1">Histoire et motivations</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=1Q7LtZyIS1f3TfeTGll3aDtWygh3GAfCb">🖥️</a>
        <a href="https://www.youtube.com/watch?v=0bMe_vCZo30">🎥</a>
      </td>
    </tr>
    <tr><td><a href="{{site.baseurl}}/fr/week01/01-2">Evolution et Apprentissage profond</a></td></tr>
    <tr>
      <td rowspan="1">Travaux dirigés</td>
      <td><a href="{{site.baseurl}}/fr/week01/01-3">Réseaux de neurones</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/01-tensor_tutorial.ipynb">📓</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/02-space_stretching.ipynb">📓</a>
        <a href="https://www.youtube.com/watch?v=5_qrxVq1kvc">🎥</a>
      </td>
    </tr>
<!-- =============================== SEMAINE 2 ================================ -->
    <tr>
      <td rowspan="3" align="center"><a href="{{site.baseurl}}/fr/week02/02">②</a></td>
      <td rowspan="2">Cours magistral</td>
      <td><a href="{{site.baseurl}}/fr/week02/02-1">Descente de gradient stochastique et rétropropagation</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=1w2jV_BT2hWzfOKBR02x_rB4-dfVUI6SR">🖥️</a>
        <a href="https://www.youtube.com/watch?v=d9vdh3b787Y">🎥</a>
      </td>
    </tr>
    <tr><td><a href="{{site.baseurl}}/fr/week02/02-2">La rétropropagation en pratique</a></td></tr>
    <tr>
      <td rowspan="1">Travaux dirigés</td>
      <td><a href="{{site.baseurl}}/fr/week02/02-3">Entraînement d’un réseau de neurones</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/01%20-%20Spiral%20classification.pdf">🖥</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/04-spiral_classification.ipynb">📓</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/05-regression.ipynb">📓</a>
        <a href="https://www.youtube.com/watch?v=WAn6lip5oWk">🎥</a>
      </td>
    </tr>
<!-- =============================== SEMAINE 3 ================================ -->
    <tr>
      <td rowspan="3" align="center"><a href="{{site.baseurl}}/fr/week03/03">③</a></td>
      <td rowspan="2">Cours magistral</td>
      <td><a href="{{site.baseurl}}/fr/week03/03-1">Transformation des paramètres</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=18UFaOGNKKKO5TYnSxr2b8dryI-PgZQmC">🖥️</a>
        <a href="https://youtu.be/FW5gFiJb-ig">🎥</a>
      </td>
    </tr>
    <tr><td><a href="{{site.baseurl}}/fr/week03/03-2">Réseaux de neurones convolutifs (ConvNets)</a></td></tr>
    <tr>
      <td rowspan="1">Travaux dirigés</td>
      <td><a href="{{site.baseurl}}/fr/week03/03-3">Propriétés des signaux naturels</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/02%20-%20CNN.pdf">🖥</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/06-convnet.ipynb">📓</a>
        <a href="https://youtu.be/kwPWpVverkw">🎥</a>
      </td>
    </tr>
<!-- =============================== SEMAINE 4 ================================ -->
    <tr>
      <td rowspan="1" align="center"><a href="{{site.baseurl}}/fr/week04/04">④</a></td>
      <td rowspan="1">Travaux dirigés</td>
      <td><a href="{{site.baseurl}}/fr/week04/04-1">Convolution à 1 dimension</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/07-listening_to_kernels.ipynb">📓</a>
        <a href="https://youtu.be/OrBEon3VlQg">🎥</a>
      </td>
    </tr>
<!-- =============================== SEMAINE 5 ================================ -->
    <tr>
      <td rowspan="3" align="center"><a href="{{site.baseurl}}/fr/week05/05">⑤</a></td>
      <td rowspan="2">Cours magistral</td>
      <td><a href="{{site.baseurl}}/fr/week05/05-1">Optimisation I</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=1pwlGN6hDFfEYQqBqcMjWbe4yfBDTxsab">🖥️</a>
        <a href="https://youtu.be/--NZb480zlg">🎥</a>
      </td>
    </tr>
    <tr><td><a href="{{site.baseurl}}/fr/week05/05-2">Optimisation II</a></td></tr>
    <tr>
      <td rowspan="1">Travaux dirigés</td>
      <td><a href="{{site.baseurl}}/fr/week05/05-3">ConvNets, autograd</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/03-autograd_tutorial.ipynb">📓</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/extra/b-custom_grads.ipynb">📓</a>
        <a href="https://youtu.be/eEzCZnOFU1w">🎥</a>
      </td>
    </tr>
<!-- =============================== SEMAINE 6 ================================ -->
    <tr>
      <td rowspan="3" align="center"><a href="{{site.baseurl}}/fr/week06/06">⑥</a></td>
      <td rowspan="2">Cours magistral</td>
      <td><a href="{{site.baseurl}}/fr/week06/06-1">Applications des ConvNets</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=1opT7lV0IRYJegtZjuHsKhlsM5L7GpGL1">🖥️</a>
        <a href="https://drive.google.com/open?id=1sdeVBC3nuh5Zkm2sqzdScEicRvLc_v-F">🖥️</a>
        <a href="https://youtu.be/ycbMGyCPzvE">🎥</a>
      </td>
    </tr>
    <tr><td><a href="{{site.baseurl}}/fr/week06/06-2">Réseaux de neurones récurrents (RNNs) et Attention</a></td></tr>
    <tr>
      <td rowspan="1">Travaux dirigés</td>
      <td><a href="{{site.baseurl}}/fr/week06/06-3">Entraîner des RNNs</a></td>
      <td>
	<a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/04%20-%20RNN.pdf">🖥️</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/08-seq_classification.ipynb">📓</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/09-echo_data.ipynb">📓</a>
        <a href="https://youtu.be/8cAffg2jaT0">🎥</a>
      </td>
    </tr>
<!-- =============================== SEMAINE 7 ================================ -->
    <tr>
      <td rowspan="3" align="center"><a href="{{site.baseurl}}/fr/week07/07">⑦</a></td>
      <td rowspan="2">Cours magistral</td>
      <td><a href="{{site.baseurl}}/fr/week07/07-1">Modèles à base d’énergie (EBMs)</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=1z8Dz1YtkOEJpU-gh5RIjORs3GGqkYJQa">🖥️</a>
        <a href="https://youtu.be/tVwV14YkbYs">🎥</a>
      </td>
    </tr>
    <tr><td><a href="{{site.baseurl}}/fr/week07/07-2">Apprentissage autosupervisé et EBMs</a></td></tr>
    <tr>
      <td rowspan="1">Travaux dirigés</td>
      <td><a href="{{site.baseurl}}/fr/week07/07-3">Auto-encodeurs</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/05%20-%20Generative%20models.pdf">🖥️</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/10-autoencoder.ipynb">📓</a>
        <a href="https://youtu.be/bggWQ14DD9M">🎥</a>
      </td>
    </tr>
<!-- =============================== SEMAINE 8 ================================ -->
    <tr>
      <td rowspan="3" align="center"><a href="{{site.baseurl}}/fr/week08/08">⑧</a></td>
      <td rowspan="2">Cours magistral</td>
      <td><a href="{{site.baseurl}}/fr/week08/08-1">Méthodes contrastives</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=1Zo_PyBEO6aNt0GV74kj8MQL7kfHdIHYO">🖥️</a>
        <a href="https://youtu.be/ZaVP2SY23nc">🎥</a>
      </td>
    </tr>
    <tr><td><a href="{{site.baseurl}}/fr/week08/08-2">Variable latente régularisée</a></td></tr>
    <tr>
      <td rowspan="1">Travaux dirigés</td>
      <td><a href="{{site.baseurl}}/fr/week08/08-3">Entraîner des Auto-Encodeurs Variationnels (VAEs)</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/05%20-%20Generative%20models.pdf">🖥️</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/11-VAE.ipynb">📓</a>
        <a href="https://youtu.be/7Rb4s9wNOmc">🎥</a>
      </td>
    </tr>
<!-- =============================== SEMAINE 9 ================================ -->
    <tr>
      <td rowspan="3" align="center"><a href="{{site.baseurl}}/fr/week09/09">⑨</a></td>
      <td rowspan="2">Cours magistral</td>
      <td><a href="{{site.baseurl}}/fr/week09/09-1">Eparsité</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=1wJRzhjSqlrSqEpX4Omagb_gdIkQ5f-6K">🖥️</a>
        <a href="https://youtu.be/Pgct8PKV7iw">🎥</a>
      </td>
    </tr>
    <tr><td><a href="{{site.baseurl}}/fr/week09/09-2">Modèles du monde, Réseaux génératifs antagonistes (GANs)</a></td></tr>
    <tr>
      <td rowspan="1">Travaux dirigés</td>
      <td><a href="{{site.baseurl}}/fr/week09/09-3">Entraîner des GANs</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/05%20-%20Generative%20models.pdf">🖥️</a>
        <a href="https://github.com/pytorch/examples/tree/master/dcgan">📓</a>
        <a href="https://youtu.be/xYc11zyZ26M">🎥</a>
      </td>
    </tr>
<!-- =============================== SEMAINE 10 =============================== -->
    <tr>
      <td rowspan="3" align="center"><a href="{{site.baseurl}}/fr/week10/10">⑩</a></td>
      <td rowspan="2">Cours magistral</td>
      <td><a href="{{site.baseurl}}/fr/week10/10-1">Apprentissage autosupervisé appliqué à la vision par ordinateur I</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=16lsnDN2HIBTcRucbVKY5B_U16c0tNQhR">🖥️</a>
        <a href="https://youtu.be/0KeR6i1_56g">🎥</a>
      </td>
    </tr>
    <tr><td><a href="{{site.baseurl}}/fr/week10/10-2"> Apprentissage autosupervisé appliqué à la vision par ordinateur II</a></td></tr>
    <tr>
      <td rowspan="1">Travaux dirigés</td>
      <td><a href="{{site.baseurl}}/fr/week10/10-3">Contrôle prédictif</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/09%20-%20Controller%20learning.pdf">🖥️</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/14-truck_backer-upper.ipynb">📓</a>
        <a href="https://youtu.be/A3klBqEWR-I">🎥</a>
      </td>
    </tr>
<!-- =============================== SEMAINE 11 =============================== -->
    <tr>
      <td rowspan="3" align="center"><a href="{{site.baseurl}}/fr/week11/11">⑪</a></td>
      <td rowspan="2">Cours magistral</td>
      <td><a href="{{site.baseurl}}/fr/week11/11-1">Fonctions d’activation</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/file/d/1AzFVLG7D4NK6ugh60f0cJQGYF5OL2sUB">🖥️</a>
        <a href="https://drive.google.com/file/d/1rkiZy0vjZqE2w7baVWvxwfAGae0Eh1Wm">🖥️</a>
        <a href="https://drive.google.com/file/d/1tryOlVAFmazLLZusD2-UfReFMkPk5hPk">🖥️</a>
        <a href="https://youtu.be/bj1fh3BvqSU">🎥</a>
      </td>
    </tr>
    <tr><td><a href="{{site.baseurl}}/fr/week11/11-2">Fonctions de perte</a></td></tr>
    <tr>
      <td rowspan="1">Travaux dirigés</td>
      <td><a href="{{site.baseurl}}/fr/week11/11-3">Prediction et apprentissage d'une politique sous incertitude</a></td>
      <td>
        <a href="http://bit.ly/PPUU-slides">🖥️</a>
        <a href="http://bit.ly/PPUU-code">📓</a>
        <a href="https://youtu.be/VcrCr-KNBHc">🎥</a>
      </td>
    </tr>
<!-- =============================== SEMAINE 12 =============================== -->
    <tr>
      <td rowspan="3" align="center"><a href="{{site.baseurl}}/fr/week12/12">⑫</a></td>
      <td rowspan="2">Cours magistral</td>
      <td><a href="{{site.baseurl}}/fr/week12/12-1">Apprentissage profond pour le traitement du langage naturel I</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/file/d/149m3wRavTp4DQZ6RJTej8KP8gv4jnkPW/">🖥️</a>
        <a href="https://youtu.be/6D4EWKJgNn0">🎥</a>
      </td>
    </tr>
    <tr><td><a href="{{site.baseurl}}/fr/week12/12-2"> Apprentissage profond pour le traitement du langage naturel II</a></td></tr>
    <tr>
      <td rowspan="1">Travaux dirigés</td>
      <td><a href="{{site.baseurl}}/fr/week12/12-3">Attention & Transformer</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/10%20-%20Attention%20%26%20transformer.pdf">🖥️</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/15-transformer.ipynb">📓</a>
        <a href="https://youtu.be/f01J0Dri-6k">🎥</a>
      </td>
    </tr>
<!-- =============================== SEMAINE 13 =============================== -->
    <tr>
      <td rowspan="3" align="center"><a href="{{site.baseurl}}/fr/week13/13">⑬</a></td>
      <td rowspan="2">Cours magistral</td>
      <td><a href="{{site.baseurl}}/fr/week13/13-1"> Réseau convolutif pour graphe I</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/file/d/1oq-nZE2bEiQjqBlmk5_N_rFC8LQY0jQr/">🖥️</a>
        <a href="https://youtu.be/Iiv9R6BjxHM">🎥</a>
      </td>
    </tr>
    <tr><td><a href="{{site.baseurl}}/fr/week13/13-2"> Réseau convolutif pour graphe II</a></td></tr>
    <tr>
      <td rowspan="1">Travaux dirigés</td>
      <td><a href="{{site.baseurl}}/fr/week13/13-3"> Réseau convolutif pour graphe III</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/11%20-%20GCN.pdf">🖥️</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/16-gated_GCN.ipynb">📓</a>
        <a href="https://youtu.be/2aKXWqkbpWg">🎥</a>
      </td>
    </tr>
<!-- =============================== SEMAINE 14 =============================== -->
    <tr>
      <td rowspan="3" align="center"><a href="{{site.baseurl}}/fr/week14/14">⑭</a></td>
      <td rowspan="2">Cours magistral</td>
      <td><a href="{{site.baseurl}}/fr/week14/14-1">Prédiction utilisant la structure</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/file/d/1qBu-2hYWaGYEXeX7kAU8O4S2RZ1hMjsk/">🖥️</a>
        <a href="https://youtu.be/gYayCG6YyO8">🎥</a>
      </td>
    </tr>
    <tr><td><a href="{{site.baseurl}}/fr/week14/14-2">Méthodes graphiques</a></td></tr>
    <tr>
      <td rowspan="1">Travaux dirigés</td>
      <td><a href="{{site.baseurl}}/fr/week14/14-3">Régularisation et réseaux bayésiens</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/07%20-%20Regularisation.pdf">🖥️</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/12-regularization.ipynb">📓</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/08%20-%20Bayesian%20NN.pdf">🖥️</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/13-bayesian_nn.ipynb">📓</a>
        <a href="https://youtu.be/DL7iew823c0">🎥</a>
      </td>
    </tr>
<!-- =============================== SEMAINE 15 =============================== -->
    <tr>
      <td rowspan="2" align="center"><a href="{{site.baseurl}}/fr/week15/15">⑮</a></td>
      <td rowspan="2">Travaux dirigés</td>
      <td><a href="{{site.baseurl}}/fr/week15/15-1">Inférence pour les EBMs à variable latente</a></td>
      <td rowspan="1">
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/12%20-%20EBM.pdf">🖥️</a>
        <a href="https://youtu.be/sbhr2wjU1-I">🎥</a>
      </td>
    </tr>
    <tr>
      <td><a href="{{site.baseurl}}/fr/week15/15-2">Entraînement des EBMs à variable latente</a></td>
      <td rowspan="1">
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/12%20-%20EBM.pdf">🖥️</a>
        <a href="https://youtu.be/XLSb1Cs1Jao">🎥</a>
      </td>
    </tr>
  </tbody>
</table>


<br><br>
<h1 style="text-align: center;">Personnes</h1>
<div class="feature__wrapper" style="text-align: center;">

    <div class="feature__item2">
        <div class="archive__item">
            <div class="archive__item-teaser">
                <img src="{{site.baseurl}}/assets/images/Yann.jpg" style="margin: 0 auto;border: 7px solid #eeeeee;border-radius: 50%;">
            </div>

            <div class="archive__item-body">
                <h3 class="archive__item-title">Yann LE CUN</h3>

                <div class="archive__item-excerpt">
                    Description à ajouter<br>
		<a href="yann@cs.nyu.edu">Email</a> | <a href="https://twitter.com/ylecun">Twitter</a> | <a href="https://www.linkedin.com/in/yann-lecun/">LinkedIn</a> | <a href="http://yann.lecun.com/">Site web</a>
                </div>

            </div>
        </div>
    </div>
    <div class="feature__item2">
        <div class="archive__item">
            <div class="archive__item-teaser">
                <img src="{{site.baseurl}}/assets/images/Alfredo.jpg" style="margin: 0 auto;border: 7px solid #eeeeee;border-radius: 50%;">
            </div>

            <div class="archive__item-body">
                <h3 class="archive__item-title">Alfredo CANZIANI</h3>

                <div class="archive__item-excerpt">
                    Description à ajouter<br>
		<a href="canziani@nyu.edu">Email</a> | <a href="https://twitter.com/alfcnz">Twitter</a> | <a href="https://www.linkedin.com/in/alfredocanziani">LinkedIn</a> | <a href="https://atcold.github.io/">Site web</a>
                </div>

            </div>
        </div>
    </div>
	
	    <div class="feature__item2">
        <div class="archive__item">
            <div class="archive__item-teaser">
                <img src="{{site.baseurl}}/assets/images/Loïck.jpg" style="margin: 0 auto;border: 7px solid #eeeeee;border-radius: 50%;">
            </div>

            <div class="archive__item-body">
                <h3 class="archive__item-title">Loïck BOURDOIS</h3>

                <div class="archive__item-excerpt">
                    Description à ajouter<br>
		<a href="loick.bourdois@outlook.com">Email</a> | <a href="https://twitter.com/BdsLoick">Twitter</a> | <a href="https://www.linkedin.com/in/lo%C3%AFck-bourdois-111488171/">LinkedIn</a> | <a href="https://lbourdois.github.io/blog/">Site web</a>
                </div>

            </div>
        </div>
    </div>
</div>

<br><br><br>
<h1 style="text-align: center;">FAQ</h1>

Voici quelques réponses à des questions fréquemment posées :<br><br>

- <b>Est-ce que suivre ce cours permet d’obtenir une certification ?</b><br>
<cite> Non. Pour proposer une certification, il faudrait pouvoir vous évaluer or le contenu n’a pas été prévu pour (contrairement à un MOOC par exemple).   
Cette demande étant fréquente, des réflexions sont menées pour essayer d’en proposer une pour des éditions (anglaises) futures du cours.</cite><br>
<br>
- <b>Combien de temps consacrer à ce cours ?</b><br>
<cite> Pour chaque semaine, il y a environ 2h30/3h de contenu vidéo. Avec le temps consacré à la prise de notes et celui pour jouer avec les <i>notebooks</i>, une estimation totale de 5h par semaine semble raisonnable. Pour la suite, cela dépend du niveau d'immersion que vous voulez atteindre dans un sujet donné (lire les articles donnés en référence, appliquer ce qui a été vu en classe à vos propres projets, etc.).</cite><br>
<br>
- <b>Où poser une question à l’issue du visionnage d’une vidéo ?</b><br>
<cite> Vous pouvez la poser directement (en anglais) dans la section commentaires sous la vidéo YouTube en question, Alfredo se fera un plaisir d’y répondre. Si cette question porte sur un point précis de la vidéo, pensez à indiquer l’horodatage. Vous pouvez le faire également sur le <a href="https://discord.gg/CthuqsX8Pb">Discord</a> de la classe dédié expressément aux étudiants. Il sert également à coordonner des groupes de visionnage, discuter des devoirs, suggérer des améliorations ou plus généralement pour tout sujet lié au cours.</cite><br>
<br>
- <b>Puis-je utiliser ce cours ?</b><br>
<cite> Bien sûr, le cours est placé sous la <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.fr"><i>Licence internationale Creative Commons Attribution-NonCommercial-ShareAlike 4.0</i></a>.
Cela signifie que :<br>
- Vous n'êtes pas autorisé à faire un usage commercial de cette œuvre.<br>
- Vous devez créditer l'œuvre, intégrer un lien vers la licence et indiquer si des modifications ont été effectuées à l'œuvre. Vous devez indiquer ces informations par tous les moyens raisonnables, sans toutefois suggérer que l'offrant vous soutient ou soutient la façon dont vous avez utilisé son œuvre.<br>
- Dans le cas où vous effectuez un remix, que vous transformez, ou créez à partir du matériel à partir de l'œuvre originale, vous devez diffuser l'œuvre modifiée dans les mêmes conditions, c'est à dire avec la même licence avec laquelle l'œuvre originale a été diffusée.<br>   
- Pour le crédit, vous pouvez utiliser le BibTeX suivant :</cite><br>
<code>
@misc{canziani2020nyudlsp20,<br>
  author = {Canziani, Alfredo and LeCun, Yann and Bourdois, Loïck},<br>
  title = {Cours d’apprentissage profond de l’Université de New York},<br>
  howpublished = "\url{https://lbourdois.github.io/cours-dl-nyu/}",<br>
  year = {2023}"}</code>
  
  
<br><br><br><br>
<h1 style="text-align: center;">Choix de traduction</h1>

- Choix de traduire les termes anglais en français :<br><br>
	
<table>
<!-- =============================== HEADER ================================ -->
  <thead>
    <tr>
      <th>Terme</th>
      <th>Traduction</th>
      <th>Raisons / Explications</th>
    </tr>
  </thead>
  <tbody>
<!-- =============================== Ligne 1 ================================ -->
    <tr>
      <td rowspan="1">Chain rule</td>
      <td rowspan="1">Règle de dérivation des fonctions composées</td>
      <td>En pratique usage du terme « règle de la chaîne » dans les sous-titres des vidéos pour gagner de la place.</td>
    </tr>
<!-- =============================== Ligne 2 ================================ -->
    <tr>
      <td rowspan="1">CNN</td>
      <td rowspan="1">ConvNet</td>
      <td>Yann tient particulièrement au respect de cette traduction. Voir notamment la page 202 du livre <a href="https://www.odilejacob.fr/catalogue/sciences/informatique/quand-la-machine-apprend_9782738149312.php">Quand la machine apprend</a>.</td>
    </tr>
<!-- =============================== Ligne 3 ================================ -->
    <tr>
      <td rowspan="1">Downstream tasks</td>
      <td rowspan="1">Tâches en aval</td>
      <td>Les tâches de prétexte étant les tâches en amont.</td>
    </tr>
<!-- =============================== Ligne 4 ================================ -->
    <tr>
      <td rowspan="1">Energy-Based Models</td>
      <td rowspan="1">Modèles à base d’énergie</td>
      <td>Traduction pas forcément satisfaisante mais adoptée faute de mieux.</td>
    </tr>
<!-- =============================== Ligne 5 ================================ -->
    <tr>
      <td rowspan="1">Embedding</td>
      <td rowspan="1">Enchâssement</td>
      <td>Reprise de la traduction utilisée page 228 dans le livre <i>Quand la machine apprend</i>. Dans la littérature, il est possible de trouver également l'usage du terme « plongement » comme traduction. Parler tout simplement de vectorisation paraîtrait beaucoup plus simple pour faire le lien avec le concept mathématique (on vectorise un mot par exemple).</td>
    </tr>
<!-- =============================== Ligne 6 ================================ -->
    <tr>
      <td rowspan="1">Graph Neural Networks</td>
      <td rowspan="1">Réseaux de neurones pour graphe</td>
      <td>En pratique, pour les sous-titres des vidéos, l'abréviation GNN est privilégiée.</td>
    </tr>
<!-- =============================== Ligne 7 ================================ -->
    <tr>
      <td rowspan="1">Graph Convolution Networks</td>
      <td rowspan="1">Réseaux convolutifs pour graphe</td>
      <td>En pratique, pour les sous-titres des vidéos, l'abréviation GCN est privilégiée.</td>
    </tr>
<!-- =============================== Ligne 8 ================================ -->
    <tr>
      <td rowspan="1">Manifold</td>
      <td rowspan="1">Variété</td>
      <td>Voir <a href="https://fr.wikipedia.org/wiki/Vari%C3%A9t%C3%A9_(g%C3%A9om%C3%A9trie)">l'article Wikipédia</a></td>
    </tr>
<!-- =============================== Ligne 9 ================================ -->
    <tr>
      <td rowspan="1">Nonlinearity function</td>
      <td rowspan="1">Fonction non linéaire</td>
      <td>En français, on utilise également le terme de « fonction d’activation ».</td>
    </tr>
<!-- =============================== Ligne 10 ================================ -->
    <tr>
      <td rowspan="1">Overfitting</td>
      <td rowspan="1">Surentraînement</td>
      <td>Reprise de la traduction utilisée page 155 dans le livre <i>Quand la machine apprend</i>.</td>
    </tr>
<!-- =============================== Ligne 11 ================================ -->
    <tr>
      <td rowspan="1">Regularizer</td>
      <td rowspan="1">Régulariseur</td>
      <td>Néologisme préférable à régularisateur.</td>
    </tr>
<!-- =============================== Ligne 12 ================================ -->
    <tr>
      <td rowspan="1">Sparse</td>
      <td rowspan="1">Epars</td>
      <td>Pour l'expression « <i>sparse matrix</i> », nous traduisons « sparse » en « creuse » pour « matrice creuse ». Pour tous les autres cas nous utilisons « épars » ou « éparse » en fonction du genre du mot auquel l'adjectif se rapporte.</td>
    </tr>
<!-- =============================== Ligne 13 ================================ -->
    <tr>
      <td rowspan="1">Sparsity</td>
      <td rowspan="1">Eparsité</td>
      <td>Néologisme basé sur le mot « épars ».</td>
    </tr>
<!-- =============================== Ligne 14 ================================ -->
    <tr>
      <td rowspan="1">Template Matching</td>
      <td rowspan="1">Template Matching</td>
      <td>L'expression « appariement de patrons » comme traduction peut être trouvable sur le site ou dans les vidéos.</td>
    </tr>	
<!-- =============================== Ligne 15 ================================ -->
    <tr>
      <td rowspan="1">Yann LeCun</td>
      <td rowspan="1">Yann Le Cun ou Yann</td>
      <td> L'explication de l'écriture du nom de famille est donnée page 193 du livre <i>Quand la machine apprend</i>. Dans les notes en anglais des étudiants, il est possible de trouver « <i>Mr Yann LeCun</i> », « <i>Mr LeCun</i> », « <i>Doctor Yann LeCun</i> », « <i>Professor LeCun</i> », etc. Nous utilisons simplement « Yann ».</td>
    </tr>
  </tbody>
</table>

<br> 
 - Choix de ne pas traduire les termes anglais en français :<br> 
Nous avons fait le choix de ne pas traduire certains termes anglais pour des raisons pratiques. Par exemple, certains concepts nécessitent 3 ou 4 mots en français là où 1 seul suffit en anglais. Cela pose notamment problème pour les vidéos où le temps d'affichage est limité, d'où la préférence à garder le terme en anglais. Il serait possible d'utiliser des néologismes mais nous avons préféré ne pas en imposer car ne pouvant peut-être pas faire consensus. Sur le site, les mots laissés en anglais sont indiqués en italique. 
<br><br>
	
<table>
<!-- =============================== HEADER ================================ -->
  <thead>
    <tr>
      <th>Terme</th>
      <th>Traduction</th>
      <th>Raisons / Explications</th>
    </tr>
  </thead>
  <tbody>
<!-- =============================== Ligne 1 ================================ -->
    <tr>
      <td rowspan="1">Dropout</td>
      <td rowspan="1">Dropout</td>
      <td>Le mot « décimation » serait approprié mais il est déjà utilisé en traitement du signal pour signifier « sous-échantillonnage ».</td>
    </tr>
<!-- =============================== Ligne 2 ================================ -->
    <tr>
      <td rowspan="1">Finetuning</td>
      <td rowspan="1">Finetuning</td>
      <td>Le terme « affinage » peut être trouvable dans la littérature. </td>
    </tr>
<!-- =============================== Ligne 3 ================================ -->
    <tr>
      <td rowspan="1">One hot</td>
      <td rowspan="1">One hot</td>
      <td>La notion de « vecteurs de base canonique » pourrait être utilisée mais elle est un peu technique et l'expression est plutôt longue pour traduire à peine 2 mots.  N.D.T : lorsque j'étais étudiant, dans mes cours d'algèbre linéaire, j'utilisais soit « v.b.c » pour « vecteurs de base canonique » ou bien « zérun » (pour un vecteur contenant des 0 et un 1) mais il s'agit d'une convention personnelle que je ne préfère pas imposer.</td>
    </tr>
<!-- =============================== Ligne 4 ================================ -->
    <tr>
      <td rowspan="1">Pooling</td>
      <td rowspan="1">Pooling</td>
      <td>Plusieurs traductions envisagées comme agrégation, agglomération, ou coalescence. Garder le terme en anglais est plus simple (un « max-agrégation » n'est pas très élégant par exemple).</td>
    </tr>
<!-- =============================== Ligne 5 ================================ -->
    <tr>
      <td rowspan="1">Transformer</td>
      <td rowspan="1">Transformer</td>
      <td>A COMPLETER.</td>
    </tr>
  </tbody>
</table>

<br><br><br>
<h1 style="text-align: center;">Jeu de données</h1>
La traduction du cours de l'anglais vers le français a permis de créer un corpus de données parallèles. Celui-ci est téléchargeable via le lien suivant ou sur le Hub d'Hugging Face.

	  
<br><br><br><br>
<h1 style="text-align: center;">Remerciements</h1>
Un grand merci aux conférenciers invités qui sont venus donner des présentations dans le cadre du cours :<br>
<a href="https://twitter.com/aaron_defazio">Aaron Defazio</a>, <a href="https://twitter.com/awnihannun">Awni Hannun</a>, <a href="https://twitter.com/imisra_">Ishan Misra</a>, <a href="https://twitter.com/MarcRanzato">Marc'Aurelio Ranzato</a>, <a href="https://twitter.com/ml_perception">Mike Lewis</a> et <a href="https://twitter.com/xbresson">Xavier Bresson</a>.<br>
<br>
Un autre grand merci aux personnes de l'ombre : <a href="https://twitter.com/marikgoldstein">Mark Goldstein</a>, <a href="https://twitter.com/ebetica">Zeming Lin</a> et <a href="https://twitter.com/jiachenai">Jiachen Zhu</a>.<br>

<br>
Enfin un énorme merci au plus de 190 étudiants qui ont partagé leur notes de cours :<br>
Yunya Wang, SunJoo Park, Mark Estudillo, Justin Mae,
Marina Zavalina, Peeyush Jain, Adrian Pearl, Davida Kollmar,
Derek Yen, Tony Xu, Ben Stadnick, Prasanthi Gurumurthy,
Amartya Prasad, Dongning Fang, Yuxin Tang, Sahana Upadhya,
Micaela Flores, Sheetal Laad, Brina Seidel, Aishwarya Rajan,
Jiuhong Xiao, Trieu Trinh, Elliot Silva, Calliea Pan,
Chris Ick, Soham Tamba, Ziyu Lei, Hengyu Tang,
Ashwin Bhola, Nyutian Long, Linfeng Zhang, Poornima Haridas,
Yuchi Ge, Anshan He, Shuting Gu, Weiyang Wen,
Vaibhav Gupta, Himani Shah, Gowri Addepalli, Lakshmi Addepalli,
Guido Petri, Haoyue Ping, Chinmay Singhal, Divya Juneja,
Leyi Zhu, Siqi Wang, Tao Wang, Anqi Zhang,
Shiqing Li, Chenqin Yang, Yakun Wang, Jimin Tan,
Jiayao Liu, Jialing Xu, Zhengyang Bian, Christina Dominguez,
Zhengyuan Ding, Biao Huang, Lin Jiang, Nhung Le,
Karanbir Singh Chahal，Meiyi He, Alexander Gao, Weicheng Zhu,
Ravi Choudhary，B V Nithish Addepalli, Syed Rahman，Jiayi Du,
Xinmeng Li, Atul Gandhi, Li Jiang, Xiao Li,
Vishwaesh Rajiv, Wenjun Qu, Xulai Jiang, Shuya Zhao,
Henry Steinitz, Rutvi Malaviya, Aathira Manoj,
Richard Pang, Aja Klevs, Hsin-Rung Chou, Mrinal Jain,
Kelly Sooch, Anthony Tse, Arushi Himatsingka, Eric Kosgey,
Bofei Zhang, Andrew Hopen, Maxwell Goldstein, Zeping Zhan,
William Huang, Kunal Gadkar, Gaomin Wu, Lin Ye,
Aniket Bhatnagar, Dhruv Goyal, Cole Smith, Nikhil Supekar,
Zhonghui Hu, Yuqing Wang, Alfred Ajay Aureate Rajakumar, Param Shah,
Muyang Jin, Jianzhi Li, Jing Qian, Zeming Lin,
Haochen Wang, Eunkyung An, Ying Jin, Ningyuan Huang,
Charles Brillo-Sonnino, Shizhan Gong, Natalie Frank, Yunan Hu,
Anuj Menta, Dipika Rajesh, Vikas Patidar, Mohith Damarapati,
Jiayu Qiu, Yuhong Zhu, Lyuang Fu, Ian Leefmans,
Trevor Mitchell, Andrii Dobroshynskyi, Shreyas Chandrakaladharan, Ben Wolfson,
Francesca Guiso, Annika Brundyn, Noah Kasmanoff, Luke Martin,
Bilal Munawar, Alexander Bienstock, Can Cui, Shaoling Chen,
Neil Menghani, Tejaishwarya Gagadam, Joshua Meisel, Jatin Khilnani,
Go Inoue, Muhammad Osama Khan, Muhammad Shujaat Mirza, Muhammad Muneeb Afzal,
Junrong Zha, Muge Chen, Rishabh Yadav, Zhuocheng Xu,
Yada Pruksachatkun, Ananya Harsh Jha, Joseph Morag, Dan Jefferys-White, Brian Kelly,
Karl Otness, Xiaoyi Zhang, Shreyas Chandrakaladharan, Chady Raach,
Yilang Hao, Binfeng Xu, Ebrahim Rasromani, Mars Wei-Lun Huang,
Anu-Ujin Gerelt-Od, Sunidhi Gupta, Bichen Kou, Binfeng Xu,
Rajashekar Vasantha,
Wenhao Li,
Vidit Bhargava, Monika Dagar,
Nandhitha Raghuram, Xinyi Zhao,
Vasudev Awatramani, Sumit Mamtani,
Srishti Bhargava, Jude Naveen Raj Ilango,
Duc Anh Phi, Krishna Karthik Reddy Jonnala,
Rahul Ahuja, jingshuai jiang,
Cal Peyser, Kevin Chang,
Gyanesh Gupta, Abed Qaddoumi,
Fanzeng Xia, Rohith Mukku,
Angela Teng, Joanna Jin,
Yang Zhou, Daniel Yao
et Sai Charitha Akula.
