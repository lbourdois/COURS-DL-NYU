---
permalink: /
title: "Cours d'apprentissage profond de la New York University"
excerpt: "Le cours de Yann LE CUN et Alfredo CANZIANI<br> traduit en français par Loïck BOURDOIS"
header:
   overlay_color: "#57068C"
layout: splash
---

</style>
<h1 style="text-align: center;">Avant-propos sur le cours</h1>
<p style="text-align:justify;">
 Ce cours, entièrement gratuit, porte sur les récentes techniques d’apprentissage profond. 
Il se concentre sur les différentes méthodes d’apprentissage (supervisé, non supervisé et autosupervisé), les différentes architectures existantes (ConvNets, RNNs, LSTMs, Transformer, GANs, GNNs, etc.), les méthodes d’enchâssement (contrastives, non-contrastives, génératives) et pleins d’autres choses !
Il est illustré d’applications à la vision par ordinateur, à la compréhension du langage naturel et à la reconnaissance vocale.<br>
Il est à souligner qu'après une présentation de la vision probabiliste de l'apprentissage profond lors du premier tiers du cours, la suite met particulièrement l'accent sur les modèles à base d'énergie (EBMs pour <i>energy based model</i>) issus de la physique.
En effet, il est possible de montrer via la distribution de Gibbs-Boltzmann, convertissant l'énergie en probabilité, que les EBMs engloblent le cadre probabiliste.
L'approche énergétique permet alors de recourir à des fonctions de perte plus souples notamment lors de l'inférence.<br>
A l'issue du cours, vous devriez être en mesure de disposer des clés pour comprendre les concepts développés par Yann dans son article <a href="https://openreview.net/forum?id=BZ5a1r-kVsf"><i>A Path Towards Autonomous Machine Intelligence</i></a>  présentant sa vision d'une voie vers l'intelligence autonome des machines.    
<br><br>
A noter que pour suivre ce cours, il est fortement conseillé d’avoir des prérequis en algèbre et d’avoir déjà suivi un cours introductif d’apprentissage machine ou de science des données. Ces cours sont destinés à des personnes de niveau bac+4 ou bac+5.</p> 
</p>
<br><br><br>

<h1 style="text-align: center;">Avant-propos sur la traduction</h1>

<p style="text-align:justify;">
La traduction française du cours agrège trois versions anglaises différentes : l'édition printemps 2020 (DLSP20 sur YouTube), l'édition printemps 2021 (DLSP21) et l'édition automne 2022 (DLFL22).<br>
Plus précisément, la totalité du cours de 2020 a été traduit. Pour les éditions 2021 et 2022, nous nous sommes limités à traduire les interventions des conférenciers invités qui étaient inédites contrairement au reste du cours qui reste très sensiblement similaire à celui de 2020.
Cependant, lors des éditions de 2021 et 2022, des actualisations de certains contenus ont pû être opérées. Ces actualisations ont également été traduites.<br><br>

Le contenu traduit représente <b>33 vidéos</b> (cours magistraux et travaux dirigés) d’une durée totale d’environ 45h, <b>74 pages web</b> de notes de cours prises par les étudiants et <b><i>16 notebooks Jupyter</i></b> utilisés lors des travaux dirigés.<br>
La manière de trouver l'ensemble du matériel du cours est décrit dans la section suivante.
</p>

<br><br><br>
<h1 style="text-align: center;">Programme</h1>


<p style="text-align:justify;">
Nous vous invitons à privilégier les vidéos de la playlist <a href="https://www.youtube.com/watch?v=0bMe_vCZo30&list=PLLHTzKZzVU9eaEyErdV26ikyolxOsz6mq">YouTube</a> (contenu « officiel ») puisque le cours y est donné par le corps enseignant contrairement aux sites web (<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/">ici</a> et <a href="https://atcold.github.io/NYU-DLSP21/fr/">ici</a>) où il s’agit des notes prises par les étudiants pendant le cours.
Les sites web étant des résumés des vidéos, celles-ci comprennent donc généralement des informations supplémentaires. Par exemple :<br>
- des anecdotes sur les différents concepts abordés,<br>
- des blagues,<br>
- la répétition d’un même concept mais sous la forme de différentes formulations permettant ainsi de comprendre une idée si une première formulation n’est pas saisie,<br> 
- les questions des étudiants qui peuvent être celles que vous ayez vous-même pendant le visionnage,<br>
Notez que si des concepts ne sont toujours pas compris à l’issue de la vidéo, vous avez la possibilité de poser une question en commentaire de la vidéo YouTube, ce que ne permet pas le site web.<br>
- les références des articles sur lesquels se basent le cours sont présentes sur les diapositives des vidéos alors qu’elles sont absentes du site. <br><br>
  
Les sites web servent ainsi davantage de résumé des vidéos ou encore de base que vous pouvez réutiliser pour vos notes personnelles que vous prenez pendant le visionnage des vidéos. 
<br><br>

Dans ce qui suit, le cours a été divisé en 19 unités. Pour chacune d'elles, vous trouverez listés dans « Ressources », les liens vers les vidéos de cours et de TD, les notes de cours, les compléments (i.e. l'actualisation de certaines parties de l'édition 2020 dans l'édition 2021), les diapositives et les <i>notebooks</i> utilisés.
</p>
<br><br>

<b><u>UNITÉ 1</u></b><br>
<p style="text-align:justify;">
• <a href="https://www.youtube.com/watch?v=0bMe_vCZo30"><b>CM : Histoire, motivation, et évolution de l’apprentissage profond</b></a><br>
<u>Concepts abordés</u> : la motivation, l’histoire et l’inspiration derrière l'apprentissage profond ; reconnaissance des motifs ; représentation hiérarchique du cortex visuel ; évolution des ConvNets et leurs applications (segmentation d'images, les véhicules autonomes et l'analyse d'images médicales).<br> 
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=0bMe_vCZo30">vidéo</a>, 
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week01/01-1/">notes de cours 1/2</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week01/01-2/">notes de cours 2/2</a>, 
<a href="https://drive.google.com/file/d/1Q7LtZyIS1f3TfeTGll3aDtWygh3GAfCb/view">diapositives</a><br>
• <a href="https://www.youtube.com/watch?v=5_qrxVq1kvc"><b>TD : Classification, algèbre linéaire, et visualisation</b></a><br>
<u>Concepts abordés</u> : algèbre linéaire et application de transformations linéaires et non linéaires.<br>
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=5_qrxVq1kvc">vidéo</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week01/01-3/">notes de cours</a>, 
<a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/01%20-%20Spiral%20classification.pdf">diapositives</a>,
<a href="https://github.com/lbourdois/pytorch-Deep-Learning-Notebooks-in-French/blob/master/01-tensor_tutorial.ipynb">notebook n°1</a>,
<a href="https://github.com/lbourdois/pytorch-Deep-Learning-Notebooks-in-French/blob/master/02-space_stretching.ipynb">notebook n°2</a><br><br>

<b><u>UNITÉ 2</u></b><br>
• <a href="https://www.youtube.com/watch?v=d9vdh3b787Y"><b>CM : Descente de gradient stochastique et rétropropagation</b></a><br>
<u>Concepts abordés</u> : modèles paramétrés ; fonction de perte ; méthodes basées sur le gradient (stochastique) ; l'algorithme de rétropropagation et des astuces pratiques la concernant.<br> 
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=d9vdh3b787Y">vidéo</a>, 
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week02/02-1/">notes de cours 1/2</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week02/02-2/">notes de cours 2/2</a>, 
<a href="https://drive.google.com/file/d/1w2jV_BT2hWzfOKBR02x_rB4-dfVUI6SR/view">diapositives</a><br>
• <a href="https://www.youtube.com/watch?v=WAn6lip5oWk"><b>TD : Entraînement d'un réseau de neurones</b></a><br>
<u>Concepts abordés</u> : conventions utilisées pour entraîner un réseau de neurones ; entraînement d'un réseau en Pytorch pour de la classification multi-classes.<br>
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=WAn6lip5oWk">vidéo</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week02/02-3/">notes de cours</a>, 
<a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/01%20-%20Spiral%20classification.pdf">diapositives</a>,
<a href="https://github.com/lbourdois/pytorch-Deep-Learning-Notebooks-in-French/blob/master/04-spiral_classification.ipynb">notebook 1</a>,
<a href="https://github.com/lbourdois/pytorch-Deep-Learning-Notebooks-in-French/blob/master/05-regression.ipynb">notebook 2</a><br><br>

<b><u>UNITÉ 3</u></b><br>
• <a href="https://www.youtube.com/watch?v=FW5gFiJb-ig"><b>CM : Réseaux de neurones convolutifs (ConvNets)</b></a><br>
<u>Concepts abordés</u> : ConvNets pour la tâche de reconnaissance des chiffres de MNIST ; noyau de convolution ; caractéristiques hiérarchiques ; propriétés de compositionnalité, de stationnarité et de localité des images.<br> 
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=FW5gFiJb-ig">vidéo</a>, 
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week03/03-1/">notes de cours 1/2</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week03/03-2/">notes de cours 2/2</a>, 
<a href="https://drive.google.com/file/d/1Q7LtZyIS1f3TfeTGll3aDtWygh3GAfCb/view">diapositives</a><br>
• <a href="https://www.youtube.com/watch?v=kwPWpVverkw"><b>TD : Propriétés des signaux naturels et ConvNets</b></a><br>
<u>Concepts abordés</u> : propriétés de compositionnalité, de stationnarité et de localité des images ; utilisation de l'éparsité par le noyau ; partage des poids et l'empilement des couches dans un réseau de neurones.<br>
<b>Ressources : </b><a href="https://www.youtube.com/watch?v=kwPWpVverkw">vidéo</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week03/03-3/">notes de cours</a>, 
<a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/01%20-%20Spiral%20classification.pdf">diapositives</a>,
<a href="https://github.com/lbourdois/pytorch-Deep-Learning-Notebooks-in-French/blob/master/06-convnet.ipynb">notebook</a><br><br>

<b><u>UNITÉ 4</u></b><br>
• <a href="https://www.youtube.com/watch?v=OrBEon3VlQg"><b>TD : Ecouter les convolutions</b></a><br>
<u>Concepts abordés</u> : algèbre linéaire ; convolutions appliquées à des données audios ; matrice de Toeplitz. <br> 
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=OrBEon3VlQg">vidéo</a>, 
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week04/04-1/">notes de cours</a>,
<a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/01%20-%20Spiral%20classification.pdf">diapositives</a>,
<a href="https://github.com/lbourdois/pytorch-Deep-Learning-Notebooks-in-French/blob/master/07-listening_to_kernels.ipynb">notebook 1</a><br><br>

<b><u>UNITÉ 5</u></b><br>
• <a href="https://www.youtube.com/watch?v=--NZb480zlg"><b>CM : Optimisation</b></a><br>
<u>Concepts abordés</u> : descente de gradient (stochastique) et mise à jour du momentum ; méthodes adaptatives pour la SGD telles que RMSprop et ADAM ; effets des couches de normalisation ; application à des scans d'IRM.<br> 
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=--NZb480zlg">vidéo</a>, 
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week05/05-1/">notes de cours 1/2</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week05/05-2/">notes de cours 2/2</a>, 
<a href="https://drive.google.com/file/d/1Q7LtZyIS1f3TfeTGll3aDtWygh3GAfCb/view">diapositives</a><br>
• <a href="https://www.youtube.com/watch?v=eEzCZnOFU1w"><b>TD : Convolution multi-canaux 1D et autograd</b></a><br>
<u>Concepts abordés</u> : multiplications matricielles et convolution 1D et 2D ; fonctionnement de la fonction <code>autograd</code>.<br>
<b>Ressources : 
</b><a href="https://www.youtube.com/watch?v=eEzCZnOFU1w">vidéo</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week01/05-3/">notes de cours</a>, 
<a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/01%20-%20Spiral%20classification.pdf">diapositives</a>,
<a href="https://github.com/lbourdois/pytorch-Deep-Learning-Notebooks-in-French/blob/master/03-autograd_tutorial.ipynb">notebook</a><br><br>

<b><u>UNITÉ 6</u></b><br>
• <a href="https://www.youtube.com/watch?v=ycbMGyCPzvE"><b>CM : Applications des ConvNets, RNNs et attention</b></a><br>
<u>Concepts abordés</u> : applications des ConvNets : reconnaissance de chiffres et d'un code postal à 5 chiffres, détection de visage en architecture multi-échelle, système de vision robotique et segmentation d'objets dans un environnement urbain ; réseaux neuronaux récurrents (RNNs), l'attention, les GRUs (<i>Gated Recurrent Unit</i>) et les LSTMs (<i>Long Short-Term</i>) contre la disparition/explosion du gradient.<br> 
<b>Ressources : 
</b><a href="https://www.youtube.com/watch?v=ycbMGyCPzvE">vidéo</a>, 
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week06/06-1/">notes de cours 1/2</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week06/06-2/">notes de cours 2/2</a>, 
<a href="https://drive.google.com/file/d/1Q7LtZyIS1f3TfeTGll3aDtWygh3GAfCb/view">diapositives</a><br>
• <a href="https://www.youtube.com/watch?v=8cAffg2jaT0"><b>TD : Architectures des RNNs et des LSTMs</b></a><br>
<u>Concepts abordés</u> : comparaison des RNNs et des LSTMs (architectures et performances).<br>
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=8cAffg2jaT0">vidéo</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week06/06-3/">notes de cours</a>, 
<a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/01%20-%20Spiral%20classification.pdf">diapositives</a>,
<a href="https://github.com/lbourdois/pytorch-Deep-Learning-Notebooks-in-French/blob/master/08-seq_classification.ipynb">notebook 1</a>,
<a href="https://github.com/lbourdois/pytorch-Deep-Learning-Notebooks-in-French/blob/master/09-echo_data.ipynb">notebook 2</a><br><br>

<b><u>UNITÉ 7</u></b><br>
• <a href="https://www.youtube.com/watch?v=tVwV14YkbYs"><b>CM : Modèles à base d’énergie (EBMs) et apprentissage autosupervisé</b></a><br>
<u>Concepts abordés</u> : EBMs à variables latentes pour avoir plusieurs prédictions possibles ; démonstration qu'un EBM peut être vu comme une généralisation d'un modèle probabiliste avec des fonctions de notation plus flexibles ; apprentissage autosupervisé ; entraînement d'un EBM en prenant l'exemple des K-means ; méthodes contrastives expliquées à l'aide d'une carte topographique.<br> 
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=tVwV14YkbYs">vidéo</a>, 
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week07/07-1/">notes de cours 1/2</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week07/07-2/">notes de cours 2/2</a>, 
<a href="https://drive.google.com/file/d/1Q7LtZyIS1f3TfeTGll3aDtWygh3GAfCb/view">diapositives</a><br>
• <a href="https://www.youtube.com/watch?v=bggWQ14DD9M"><b>TD : Auto-encodeurs sous/sur-complets</b></a><br>
<u>Concepts abordés</u> : applications des auto-encodeurs ; différentes architectures d'auto-encodeurs (couche cachée complète ou non) ; implémentation d'un auto-encodeur standard et d'un auto-encodeur débruiteur.<br>
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=bggWQ14DD9M">vidéo</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week07/07-3/">notes de cours</a>,
<a href="https://atcold.github.io/NYU-DLSP21/fr/week07/07-3/">compléments</a>,
<a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/01%20-%20Spiral%20classification.pdf">diapositives</a>,
<a href="https://github.com/lbourdois/pytorch-Deep-Learning-Notebooks-in-French/blob/master/10-autoencoder.ipynb">notebook</a><br><br>

<b><u>UNITÉ 8</u></b><br>
• <a href="https://www.youtube.com/watch?v=ZaVP2SY23nc"><b>CM : Méthodes constratives et modèles à variable latente régularisée</b></a><br>
<u>Concepts abordés</u> : méthodes contrastives dans l'apprentissage autosupervisé ; auto-encodeurs débruiteurs ; EBMs à variables latentes régularisées ; algorithmes ISTA, FISTA et LISTA ; auto-encodeurs variationnels et concepts sous-jacents.<br> 
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=ZaVP2SY23nc">vidéo</a>, 
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week08/08-1/">notes de cours 1/2</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week08/08-2/">notes de cours 2/2</a>, 
<a href="https://drive.google.com/file/d/1Q7LtZyIS1f3TfeTGll3aDtWygh3GAfCb/view">diapositives</a><br>
• <a href="https://www.youtube.com/watch?v=7Rb4s9wNOmc"><b>TD : Auto-encodeurs variationnels (VAEs)</b></a><br>
<u>Concepts abordés</u> : comparaison auto-encodeurs variationnels (VAEs) et auto-encodeurs (AE) standards ; implémentation d'un VAE sur le jeu de données MNIST pour générer de nouveaux échantillons.<br>
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=7Rb4s9wNOmc">vidéo</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week08/08-3/">notes de cours</a>, 
<a href="https://atcold.github.io/NYU-DLSP21/fr/week08/08-3/">compléments</a>,

<a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/01%20-%20Spiral%20classification.pdf">diapositives</a>,
<a href="https://github.com/lbourdois/pytorch-Deep-Learning-Notebooks-in-French/blob/master/11-VAE.ipynb">notebook</a><br><br>

<b><u>UNITÉ 9</u></b><br>
• <a href="https://www.youtube.com/watch?v=Pgct8PKV7iw"><b>CM : Eparsité de groupe, modèle du monde et GANs</b></a><br>
<u>Concepts abordés</u> : auto-encodeurs épars récurrents discriminatifs et éparsité de groupe pour extraire des caractéristiques invariantes ; architecture de modèles du monde pour le contrôle autonome ; différence entre les modèles du monde et l'apprentissage par renforcement ; réseaux génératifs antagonistes (GANs) en termes d'EBM contrastif.
<br> 
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=Pgct8PKV7iw">vidéo</a>, 
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week09/09-1/">notes de cours 1/2</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week09/09-2/">notes de cours 2/2</a>, 
<a href="https://drive.google.com/file/d/1Q7LtZyIS1f3TfeTGll3aDtWygh3GAfCb/view">diapositives</a><br>
• <a href="https://www.youtube.com/watch?v=xYc11zyZ26M"><b>TD : GANs vus à travers les EBMs</b></a><br>
<u>Concepts abordés</u> : réseaux génératifs antagonistes (GANs) ; comparaison entre GANs et VAEs ; examen du code du <i>Deep Convolutional Generative Adversarial Networks</i> (DCGAN).<br>
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=xYc11zyZ26M">vidéo</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week09/09-3/">notes de cours</a>, 
<a href="https://atcold.github.io/NYU-DLSP21/fr/week09/09-3/">compléments</a>,
<a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/01%20-%20Spiral%20classification.pdf">diapositives</a>,
<a href="https://github.com/lbourdois/pytorch-Deep-Learning-Notebooks-in-French/blob/master/01-tensor_tutorial.ipynb">notebook 1</a>,
<a href="https://github.com/lbourdois/pytorch-Deep-Learning-Notebooks-in-French/blob/master/02-space_stretching.ipynb">notebook 2</a><br><br>

<b><u>UNITÉ 10</u></b><br>
• <a href="https://www.youtube.com/watch?v=0KeR6i1_56g"><b>CM : Apprentissage autosupervisé en vision par ordinateur</b></a><br>
<u>Concepts abordés</u> : apprentissage autosupervisé en vision par ordinateur ; tâches de prétexte en images, en vidéos et en vidéos avec du son ; clustering et l'apprentissage contrastif ; méthodes ClusterFit et PIRL.<br> 
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=0KeR6i1_56g">vidéo</a>, 
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week10/10-1/">notes de cours 1/2</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week10/10-2/">notes de cours 2/2</a>, 
<a href="https://drive.google.com/file/d/1Q7LtZyIS1f3TfeTGll3aDtWygh3GAfCb/view">diapositives</a><br>
• <a href="https://www.youtube.com/watch?v=A3klBqEWR-I"><b>TD : Le <i>Truck Backer-Upper</i></b></a><br>
<u>Concepts abordés</u> :  problème du <i>Truck Backer-Upper</i> (Nguyen & Widrow, '90) ; résoudre un problème de contrôle non linéaire à l'aide de réseaux de neurones.<br>
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=A3klBqEWR-I">vidéo</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week10/10-3/">notes de cours</a>, 
<a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/01%20-%20Spiral%20classification.pdf">diapositives</a>,
<a href="https://github.com/lbourdois/pytorch-Deep-Learning-Notebooks-in-French/blob/master/14-truck_backer-upper.ipynb">notebook</a><br><br>

<b><u>UNITÉ 11</u></b><br>
• <a href="https://www.youtube.com/watch?v=bj1fh3BvqSU"><b>CM : Fonctions d’activation et de perte sur PyTorch</b></a><br>
<u>Concepts abordés</u> : fonctions d'activation courantes dans Pytorch ; comparaison activations avec coude(s) et les activations lisses ; pertes basées sur une marge et leurs applications notamment dans le cadre des EBMs.<br> 
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=bj1fh3BvqSU">vidéo</a>, 
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week11/11-1/">notes de cours 1/2</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week11/11-2/">notes de cours 2/2</a>, 
<a href="https://drive.google.com/file/d/1Q7LtZyIS1f3TfeTGll3aDtWygh3GAfCb/view">diapositives</a><br>
• <a href="https://www.youtube.com/watch?v=VcrCr-KNBHc"><b>TD : La prédiction et l’apprentissage de politique sous contrainte (PPUU)</b></a><br>
<u>Concepts abordés</u> : apprentissage efficace des politiques pour conduire dans un trafic dense ; minimisation de l'incertitude dans la prédiction du modèle.<br>
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=VcrCr-KNBHc">vidéo</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week11/11-3/">notes de cours</a>, 
<a href="https://atcold.github.io/NYU-DLSP21/fr/week12/12-3/">compléments</a>,
<a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/01%20-%20Spiral%20classification.pdf">diapositives</a>,
<a href="https://github.com/Atcold/pytorch-PPUU">notebook</a><br><br>

<b><u>UNITÉ 12</u></b><br>
• <a href="https://www.youtube.com/watch?v=6D4EWKJgNn0"><b>CM : Apprentissage profond pour le traitement du langage naturel</b></a><br>
<u>Concepts abordés</u> : traitement du langage naturel ; modules composant les <i>transformers</i> et astuces permettant de les entraîner de manière efficace ; recherche en faisceau, décodage gourmand et recherche exhaustive ; échantillonnage top-k ; word2vec, GPT et BERT.<br>
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=6D4EWKJgNn0">vidéo</a>, 
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week12/12-1/">notes de cours 1/2</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week12/12-2/">notes de cours 2/2</a>, 
<a href="https://drive.google.com/file/d/1Q7LtZyIS1f3TfeTGll3aDtWygh3GAfCb/view">diapositives</a><br>
• <a href="https://www.youtube.com/watch?v=f01J0Dri-6k"><b>TD : L’attention et le <i>transformer</i></b></a><br>
<u>Concepts abordés</u> : attention et auto-attention ; concept de requêtes, clés et valeurs ; implémentation d'un transformer standard ; comparaison du paradigme de l'encodeur-décodeur aux architectures séquentielles.<br>
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=f01J0Dri-6k">vidéo</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week12/12-3/">notes de cours</a>, 
<a href="https://atcold.github.io/NYU-DLSP21/fr/week10/10-3/">compléments</a>,
<a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/01%20-%20Spiral%20classification.pdf">diapositives</a>,
<a href="https://github.com/lbourdois/pytorch-Deep-Learning-Notebooks-in-French/blob/master/15-transformer.ipynb">notebook</a><br><br>

<b><u>UNITÉ 13</u></b><br>
• <a href="https://www.youtube.com/watch?v=Iiv9R6BjxHM"><b>CM : Les réseaux de neurones convolutifs pour graphes (GCNs)</b></a><br>
<u>Concepts abordés</u> : réseaux convolutifs pour graphe (GCN) ; les réseaux spectraux (via convolution spectrale) et les réseaux spatiaux (via <i>template matching</i>) ; avantages et inconvénients, expériences, <i>benchmarks</i> et applications de ces architectures.<br> 
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=Iiv9R6BjxHM">vidéo</a>, 
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week13/13-1/">notes de cours 1/2</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week13/13-2/">notes de cours 2/2</a>, 
<a href="https://drive.google.com/file/d/1Q7LtZyIS1f3TfeTGll3aDtWygh3GAfCb/view">diapositives</a><br>
• <a href="https://www.youtube.com/watch?v=2aKXWqkbpWg"><b>TD : Les réseaux de neurones pour graphes (GNNs)</b></a><br>
<u>Concepts abordés</u> : connexion entre GCN et l'auto-attention ; implémentation d'un <i>Residual Gated GCN</i>.<br>
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=2aKXWqkbpWg">vidéo</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week13/13-3/">notes de cours</a>, 
<a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/01%20-%20Spiral%20classification.pdf">diapositives</a>,
<a href="https://github.com/lbourdois/pytorch-Deep-Learning-Notebooks-in-French/blob/master/16-gated_GCN.ipynb">notebook</a><br><br>

<b><u>UNITÉ 14</u></b><br>
• <a href="https://www.youtube.com/watch?v=gYayCG6YyO8"><b>CM : Prédiction utilisant la structure avec les EBMs</b></a><br>
<u>Concepts abordés</u> : prédiction basée sur la structure ; graphe factoriel basé sur l'énergie ; algorithme de Viterbi et algorithme <i>forward</i> appliqués aux <i>Graph Transformer Networks</i> ; formulation lagrangienne de la rétropropagation ; inférence variationnelle pour les modèles à base d'énergie.<br> 
<b>Ressources : 
</b><a href="https://www.youtube.com/watch?v=gYayCG6YyO8">vidéo</a>, 
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week14/14-1/">notes de cours 1/2</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week14/14-2/">notes de cours 2/2</a>, 
<a href="https://drive.google.com/file/d/1Q7LtZyIS1f3TfeTGll3aDtWygh3GAfCb/view">diapositives</a><br>
• <a href="https://www.youtube.com/watch?v=DL7iew823c0"><b>TD : Surapprentissage et régularisation, et réseaux de neurones bayésiens</b></a><br>
<u>Concepts abordés</u> : Effet du surentraînement ; méthodes de régularisation pour réduire le surentraînement ; réseaux de neurones bayésiens.<br>
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=DL7iew823c0">vidéo</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week14/14-3/">notes de cours</a>, 
<a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/01%20-%20Spiral%20classification.pdf">diapositives</a>,
<a href="https://github.com/lbourdois/pytorch-Deep-Learning-Notebooks-in-French/blob/master/12-regularization.ipynb">notebook 1</a>,
<a href="https://github.com/lbourdois/pytorch-Deep-Learning-Notebooks-in-French/blob/master/13-bayesian_nn..ipynb">notebook 2</a><br><br>

<b><u>UNITÉ 15</u></b><br>
• <a href="https://www.youtube.com/watch?v=sbhr2wjU1-I"><b>TD partie A : Inférence pour les EBMs à variable latente</b></a><br>
<u>Concepts abordés</u> : modèles à base d'énergie à variables latentes ; EBM appliqué à une ellipse.<br> 
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=sbhr2wjU1-I">vidéo</a>, 
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week15/15-1/">notes de cours</a>,
<a href="">diapositives</a><br>
• <a href="https://www.youtube.com/watch?v=XLSb1Cs1Jao"><b>TD partie B : Entraînement des EBMs à variable latente</b></a><br>
<u>Concepts abordés</u> : version relaxée de l'énergie libre via modification de la température ; exemples d'entraînement d'EBMs et notamment l'apprentissage d'une variété de données en forme de corne.<br>
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=XLSb1Cs1Jao">vidéo</a>,
<a href="https://atcold.github.io/pytorch-Deep-Learning/fr/week15/15-2/">notes de cours</a>,
<a href="">diapositives</a><br><br>

<b><u>UNITÉ 16</u></b><br>
Cette unité peut être vue comme la suite de l'unité 10.<br>
• <a href="https://www.youtube.com/watch?v=8L10w1KoOU8"><b>CM : Apprentissage autosupervisé en vision par ordinateur (suite)</b></a><br>
<u>Concepts abordés</u> : apprenttisage autosupervisé en vision ; tâches de prétexte et solution triviale ; apprentissage contrastif et régularisé ; présentations des méthodes PIRL, SimCLR, MoCo, SwAV, SEER et Barlow Twins.<br>
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=8L10w1KoOU8">vidéo</a>, 
<a href="https://atcold.github.io/NYU-DLSP21/fr/week10/10-1/">notes de cours 1/2</a>,
<a href="https://atcold.github.io/NYU-DLSP21/fr/week10/10-2/">notes de cours 2/2</a>, 
<a href="https://drive.google.com/file/d/1BQlWMVesOcioW69RCKWCjp6280Q42W9q/edit">diapositives</a><br><br>

<b><u>UNITÉ 17</u></b><br>
• <a href="https://www.youtube.com/watch?v=Of9s8epjflU"><b>CM : Reconnaissance vocale et <i>Graph Transformer Networks</i></b></a><br>
<u>Concepts abordés</u> : reconnaissance de la parole ; perte CTC (<i>Connectionist Temporal Classification</i>) ; recherche en faisceau pendant l’inférence ; entraînement d’un <i>Graph Transformer Network</i> (GTN) ; « accepteur d’état fini pondéré » (WFSA pour « <i>Weighted Finite State Acceptor</i> ») pour encoder des a priori dans un graphe ; opérations des états finis pondérés (union, étoile de Kleene, intersection, composition).<br> 
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=Of9s8epjflU">vidéo</a>, 
<a href="https://atcold.github.io/NYU-DLSP21/fr/week11/11-1/">notes de cours 1/2</a>,
<a href="https://atcold.github.io/NYU-DLSP21/fr/week11/11-2/">notes de cours 2/2</a>, 
<a href="https://drive.google.com/file/d/1-u2fSSICaWoFu91oiMsd2mAhg6ZGomMg/edit">diapositives</a><br><br>

<b><u>UNITÉ 18</u></b><br>
• <a href="https://www.youtube.com/watch?v=fR42OOy9ROo"><b>CM : Traduction automatique à faibles ressources</b></a><br>
<u>Concepts abordés</u> : traduction automatique neuronale à faibles ressources ; cycle de la recherche ; incompatibilités potentielles entre les domaines.<br> 
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=fR42OOy9ROo">vidéo</a>, 
<a href="https://atcold.github.io/NYU-DLSP21/fr/week12/12-1/">notes de cours 1/2</a>,
<a href="https://atcold.github.io/NYU-DLSP21/fr/week12/12-2/">notes de cours 2/2</a>,  
<a href="https://drive.google.com/file/d/1pm1fM1DFqCHrjGorCQCwg5SgMjwZBwGR/edit">diapositives</a><br><br>

<b><u>UNITÉ 19</u></b><br>
Cette unité peut être vue comme la suite des vidéos d'Ishan Misra (unités 10 et 16) puisque nous traitons de l’apprentissage de représentations visuelles avec l’apprentissage autosupervisé.<br>
• <a href="https://www.youtube.com/watch?v=5VjEBHWuYs8"><b>TD : Méthodes d'enchâssements joints contrastives</b></a><br>
<u>Concepts abordés</u> : modèles génératifs ; tâches de prétexte et solution triviale ; méthodes d’enchâssements joints (JEMs) contrastives.<br> 
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=5VjEBHWuYs8">vidéo</a>, 
<a href="https://atcold.github.io/NYU-DLSP21/fr/week15/15-1/">notes de cours</a>,
<a href="">diapositives</a><br>
<a href="https://www.youtube.com/watch?v=EBrbaD2zyuo"><b>TD : Méthodes d'enchâssements joints régularisées</b></a><br>
<u>Concepts abordés</u> : méthodes non-contrastives et théorie de l’information ; méthodes de clustering ; « autres méthodes » ; suggestions d'améliorations des JEMs.<br> 
<b>Ressources : </b>
<a href="https://www.youtube.com/watch?v=EBrbaD2zyuo">vidéo</a>, 
<a href="https://atcold.github.io/NYU-DLSP21/fr/week15/15-2/">notes de cours</a>,
<a href="">diapositives</a><br><br>
</p>


<br><br>
<h1 style="text-align: center;">Personnes</h1>
<div class="feature__wrapper" style="text-align: center;">

    <div class="feature__item2">
        <div class="archive__item">
            <div class="archive__item-teaser">
                <img src="{{site.baseurl}}/assets/images/Yann.jpg" style="margin: 0 auto;border: 7px solid #eeeeee;border-radius: 50%;">
            </div>

            <div class="archive__item-body">
                <h3 class="archive__item-title">Yann LE CUN</h3>

                <div class="archive__item-excerpt">
                    Description à ajouter<br>
		<a href="yann@cs.nyu.edu">Email</a> | <a href="https://twitter.com/ylecun">Twitter</a> | <a href="https://www.linkedin.com/in/yann-lecun/">LinkedIn</a> | <a href="http://yann.lecun.com/">Site web</a>
                </div>

            </div>
        </div>
    </div>
    <div class="feature__item2">
        <div class="archive__item">
            <div class="archive__item-teaser">
                <img src="{{site.baseurl}}/assets/images/Alfredo.jpg" style="margin: 0 auto;border: 7px solid #eeeeee;border-radius: 50%;">
            </div>

            <div class="archive__item-body">
                <h3 class="archive__item-title">Alfredo CANZIANI</h3>

                <div class="archive__item-excerpt">
                    Description à ajouter<br>
		<a href="canziani@nyu.edu">Email</a> | <a href="https://twitter.com/alfcnz">Twitter</a> | <a href="https://www.linkedin.com/in/alfredocanziani">LinkedIn</a> | <a href="https://atcold.github.io/">Site web</a>
                </div>

            </div>
        </div>
    </div>
	
	    <div class="feature__item2">
        <div class="archive__item">
            <div class="archive__item-teaser">
                <img src="{{site.baseurl}}/assets/images/Loïck.jpg" style="margin: 0 auto;border: 7px solid #eeeeee;border-radius: 50%;">
            </div>

            <div class="archive__item-body">
                <h3 class="archive__item-title">Loïck BOURDOIS</h3>

                <div class="archive__item-excerpt">
                    Description à ajouter<br>
		<a href="loick.bourdois@outlook.com">Email</a> | <a href="https://twitter.com/BdsLoick">Twitter</a> | <a href="https://www.linkedin.com/in/lo%C3%AFck-bourdois-111488171/">LinkedIn</a> | <a href="https://lbourdois.github.io/blog/">Site web</a>
                </div>

            </div>
        </div>
    </div>
</div>

<br><br><br>
<h1 style="text-align: center;">FAQ</h1>
<p style="text-align:justify;">
- <b>Est-ce que suivre ce cours permet d’obtenir une certification ?</b><br>
<cite> Non. Pour proposer une certification, il faudrait pouvoir vous évaluer or le contenu n’a pas été prévu pour (contrairement à un MOOC par exemple).   
Cette demande étant fréquente, des réflexions sont menées pour essayer d’en proposer une pour des éditions (anglaises) futures du cours.</cite><br>
<br>
- <b>Combien de temps consacrer à ce cours ?</b><br>
<cite> Pour chaque semaine, il y a environ 2h30/3h de contenu vidéo. Avec le temps consacré à la prise de notes et celui pour jouer avec les <i>notebooks</i>, une estimation totale de 5h par semaine semble raisonnable. Pour la suite, cela dépend du niveau d'immersion que vous voulez atteindre dans un sujet donné (lire les articles donnés en référence, appliquer ce qui a été vu en classe à vos propres projets, etc.).</cite><br>
<br>
- <b>Où poser une question à l’issue du visionnage d’une vidéo ?</b><br>
<cite> Vous pouvez la poser directement (en anglais) dans la section commentaires sous la vidéo YouTube en question, Alfredo se fera un plaisir d’y répondre. Si cette question porte sur un point précis de la vidéo, pensez à indiquer l’horodatage. Vous pouvez le faire également sur le <a href="https://discord.gg/CthuqsX8Pb">Discord</a> de la classe dédié expressément aux étudiants. Il sert également à coordonner des groupes de visionnage, discuter des devoirs, suggérer des améliorations ou plus généralement pour tout sujet lié au cours.</cite><br>
<br>
- <b>Puis-je utiliser ce cours ?</b><br>
<cite> Bien sûr, le cours est placé sous la <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.fr"><i>Licence internationale Creative Commons Attribution-NonCommercial-ShareAlike 4.0</i></a>.
Cela signifie que :<br>
- Vous n'êtes pas autorisé à faire un usage commercial de cette œuvre.<br>
- Vous devez créditer l'œuvre, intégrer un lien vers la licence et indiquer si des modifications ont été effectuées à l'œuvre. Vous devez indiquer ces informations par tous les moyens raisonnables, sans toutefois suggérer que l'offrant vous soutient ou soutient la façon dont vous avez utilisé son œuvre.<br>
- Dans le cas où vous effectuez un remix, que vous transformez, ou créez à partir du matériel à partir de l'œuvre originale, vous devez diffuser l'œuvre modifiée dans les mêmes conditions, c'est à dire avec la même licence avec laquelle l'œuvre originale a été diffusée.<br>   
- Pour le crédit, vous pouvez utiliser le BibTeX suivant :</cite><br>
</p>
<code>
@misc{nyudlcourseinfrench,<br>
  author = {Canziani, Alfredo and LeCun, Yann and Bourdois, Loïck},<br>
  title = {Cours d’apprentissage profond de la New York University},<br>
  howpublished = "\url{https://lbourdois.github.io/cours-dl-nyu/}",<br>
  year = {2023}"}</code>

  
<br><br><br><br>
<h1 style="text-align: center;">Choix de traduction</h1>

- Choix de traduire les termes anglais en français :<br><br>
	
<table>
<!-- =============================== HEADER ================================ -->
  <thead>
    <tr>
      <th>Terme</th>
      <th>Traduction</th>
      <th>Raisons / Explications</th>
    </tr>
  </thead>
  <tbody>
<!-- =============================== Ligne 1 ================================ -->
    <tr>
      <td rowspan="1">Chain rule</td>
      <td rowspan="1">Règle de dérivation des fonctions composées</td>
      <td>En pratique usage du terme « règle de la chaîne » dans les sous-titres des vidéos pour gagner de la place.</td>
    </tr>
<!-- =============================== Ligne 2 ================================ -->
    <tr>
      <td rowspan="1">CNN</td>
      <td rowspan="1">ConvNet</td>
      <td>Yann tient particulièrement au respect de cette traduction. Voir notamment la page 202 du livre <a href="https://www.odilejacob.fr/catalogue/sciences/informatique/quand-la-machine-apprend_9782738149312.php">Quand la machine apprend</a>.</td>
    </tr>
<!-- =============================== Ligne 3 ================================ -->
    <tr>
      <td rowspan="1">Downstream tasks</td>
      <td rowspan="1">Tâches en aval</td>
      <td>Les tâches de prétexte étant les tâches en amont.</td>
    </tr>
<!-- =============================== Ligne 4 ================================ -->
    <tr>
      <td rowspan="1">Energy-Based Models</td>
      <td rowspan="1">Modèles à base d’énergie</td>
      <td>Traduction pas forcément satisfaisante mais adoptée faute de mieux.</td>
    </tr>
<!-- =============================== Ligne 5 ================================ -->
    <tr>
      <td rowspan="1">Embedding</td>
      <td rowspan="1">Enchâssement</td>
      <td>Reprise de la traduction utilisée page 228 dans le livre <i>Quand la machine apprend</i>. Dans la littérature, il est possible de trouver également l'usage du terme « plongement » comme traduction. Parler tout simplement de vectorisation paraîtrait beaucoup plus simple pour faire le lien avec le concept mathématique (on vectorise un mot par exemple).</td>
    </tr>
<!-- =============================== Ligne 6 ================================ -->
    <tr>
      <td rowspan="1">Graph Neural Networks</td>
      <td rowspan="1">Réseaux de neurones pour graphe</td>
      <td>En pratique, pour les sous-titres des vidéos, l'abréviation GNN est privilégiée.</td>
    </tr>
<!-- =============================== Ligne 7 ================================ -->
    <tr>
      <td rowspan="1">Graph Convolution Networks</td>
      <td rowspan="1">Réseaux convolutifs pour graphe</td>
      <td>En pratique, pour les sous-titres des vidéos, l'abréviation GCN est privilégiée.</td>
    </tr>
<!-- =============================== Ligne 8 ================================ -->
    <tr>
      <td rowspan="1">Manifold</td>
      <td rowspan="1">Variété</td>
      <td>Voir <a href="https://fr.wikipedia.org/wiki/Vari%C3%A9t%C3%A9_(g%C3%A9om%C3%A9trie)">l'article Wikipédia</a></td>
    </tr>
<!-- =============================== Ligne 9 ================================ -->
    <tr>
      <td rowspan="1">Nonlinearity function</td>
      <td rowspan="1">Fonction non linéaire</td>
      <td>En français, on utilise également le terme de « fonction d’activation ».</td>
    </tr>
<!-- =============================== Ligne 10 ================================ -->
    <tr>
      <td rowspan="1">Overfitting</td>
      <td rowspan="1">Surentraînement</td>
      <td>Reprise de la traduction utilisée page 155 dans le livre <i>Quand la machine apprend</i>.</td>
    </tr>
<!-- =============================== Ligne 11 ================================ -->
    <tr>
      <td rowspan="1">Regularizer</td>
      <td rowspan="1">Régulariseur</td>
      <td>Néologisme préférable à régularisateur.</td>
    </tr>
<!-- =============================== Ligne 12 ================================ -->
    <tr>
      <td rowspan="1">Sparse</td>
      <td rowspan="1">Epars</td>
      <td>Pour l'expression « <i>sparse matrix</i> », nous traduisons « sparse » en « creuse » pour « matrice creuse ». Pour tous les autres cas nous utilisons « épars » ou « éparse » en fonction du genre du mot auquel l'adjectif se rapporte.</td>
    </tr>
<!-- =============================== Ligne 13 ================================ -->
    <tr>
      <td rowspan="1">Sparsity</td>
      <td rowspan="1">Eparsité</td>
      <td>Néologisme basé sur le mot « épars ».</td>
    </tr>
<!-- =============================== Ligne 14 ================================ -->
    <tr>
      <td rowspan="1">Template Matching</td>
      <td rowspan="1">Template Matching</td>
      <td>L'expression « appariement de patrons » comme traduction peut être trouvable sur le site ou dans les vidéos.</td>
    </tr>	
<!-- =============================== Ligne 15 ================================ -->
    <tr>
      <td rowspan="1">Yann LeCun</td>
      <td rowspan="1">Yann Le Cun ou Yann</td>
      <td> L'explication de l'écriture du nom de famille est donnée page 193 du livre <i>Quand la machine apprend</i>. Dans les notes en anglais des étudiants, il est possible de trouver « <i>Mr Yann LeCun</i> », « <i>Mr LeCun</i> », « <i>Doctor Yann LeCun</i> », « <i>Professor LeCun</i> », etc. Nous utilisons simplement « Yann ».</td>
    </tr>
  </tbody>
</table>

<br> 
 - Choix de ne pas traduire les termes anglais en français :<br> 
<p style="text-align:justify;">
Nous avons fait le choix de ne pas traduire certains termes anglais pour des raisons pratiques. Par exemple, certains concepts nécessitent 3 ou 4 mots en français là où 1 seul suffit en anglais. Cela pose notamment problème pour les vidéos où le temps d'affichage est limité, d'où la préférence à garder le terme en anglais. Il serait possible d'utiliser des néologismes mais nous avons préféré ne pas en imposer car ne pouvant peut-être pas faire consensus. Sur le site, les mots laissés en anglais sont indiqués en italique. 
</p>
<br><br>
	
<table>
<!-- =============================== HEADER ================================ -->
  <thead>
    <tr>
      <th>Terme</th>
      <th>Traduction</th>
      <th>Raisons / Explications</th>
    </tr>
  </thead>
  <tbody>
<!-- =============================== Ligne 1 ================================ -->
    <tr>
      <td rowspan="1">Dropout</td>
      <td rowspan="1">Dropout</td>
      <td>Le mot « décimation » serait approprié mais il est déjà utilisé en traitement du signal pour signifier « sous-échantillonnage ».</td>
    </tr>
<!-- =============================== Ligne 2 ================================ -->
    <tr>
      <td rowspan="1">Finetuning</td>
      <td rowspan="1">Finetuning</td>
      <td>Le terme « affinage » peut être trouvable dans la littérature. </td>
    </tr>
<!-- =============================== Ligne 3 ================================ -->
    <tr>
      <td rowspan="1">One hot</td>
      <td rowspan="1">One hot</td>
      <td>La notion de « vecteurs de base canonique » pourrait être utilisée mais elle est un peu technique et l'expression est plutôt longue pour traduire à peine 2 mots.  N.D.T : lorsque j'étais étudiant, dans mes cours d'algèbre linéaire, j'utilisais soit « v.b.c » pour « vecteurs de base canonique » ou bien « zérun » (pour un vecteur contenant des 0 et un 1) mais il s'agit d'une convention personnelle que je ne préfère pas imposer.</td>
    </tr>
<!-- =============================== Ligne 4 ================================ -->
    <tr>
      <td rowspan="1">Pooling</td>
      <td rowspan="1">Pooling</td>
      <td>Plusieurs traductions envisagées comme agrégation, agglomération, ou coalescence. Garder le terme en anglais est plus simple (un « max-agrégation » n'est pas très élégant par exemple).</td>
    </tr>
<!-- =============================== Ligne 5 ================================ -->
    <tr>
      <td rowspan="1">Transformer</td>
      <td rowspan="1">Transformer</td>
      <td>Les mots anglais se terminant par « er » sont généralement traduits par « eur », comme par exemple « encoder » en « encodeur » ou, dans la même logique, « decoder » en « decodeur ».
Logiquement, « tranformers » devrait se traduire par « transformeurs ». Mais ce n'est pas si simple.
L'article <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf">Gradient-based learning applied to document recognition</a>) est généralement cité pour ses trois premiers chapitres exposant un ConvNet appliqué à la reconnaissance MNIST. Mais les suivant traite des GTNs, les <i>Graph Transformer Networks</i>, qui sont issus du travail de Léon Bottou.
Comme leur nom l'indique, les GTNs contiennent le mot « transformer », mais cela n'a rien à voir avec celui de Vaswani et al. ayant vu le jour plus de 19 ans plus tard. 
Les articles traitent de choses différentes, il faudrait traduire le « transformer » de chaque papier différemment pour qu’il n’y ait pas de confusion entre les deux concepts.
En attendant de pouvoir trancher cette question, il a été choisi de laisser le « transformer » en sa forme anglaise indiquer en italique pour éviter une confusion supplémentaire avec le verbe « transformer » en français.
</td>
    </tr>
  </tbody>
</table>

<br><br><br>
<h1 style="text-align: center;">Jeu de données</h1>
<p style="text-align:justify;">
La traduction du cours de l'anglais vers le français a permis de créer un corpus de données parallèles. Le jeu de données a été créé et vérifier manuellement afin de s'assurer du bon alignement de l'ensemble des données.
Ce jeu de données est téléchargeable via le lien suivant ou sur le Hub d'Hugging Face.
</p>
	  
<br><br><br><br>
<h1 style="text-align: center;">Remerciements</h1>
<p style="text-align:justify;">
Un grand merci aux conférenciers invités qui sont venus donner des présentations dans le cadre du cours : <a href="https://twitter.com/aaron_defazio">Aaron Defazio</a>, <a href="https://twitter.com/awnihannun">Awni Hannun</a>, <a href="https://twitter.com/imisra_">Ishan Misra</a>, <a href="https://twitter.com/MarcRanzato">Marc'Aurelio Ranzato</a>, <a href="https://twitter.com/ml_perception">Mike Lewis</a> et <a href="https://twitter.com/xbresson">Xavier Bresson</a>.<br>
<br>
Un autre grand merci aux personnes de l'ombre : <a href="https://twitter.com/marikgoldstein">Mark Goldstein</a>, <a href="https://twitter.com/ebetica">Zeming Lin</a> et <a href="https://twitter.com/jiachenai">Jiachen Zhu</a>.<br>

<br>
Enfin un énorme merci au plus de 190 étudiants qui ont partagé leur notes de cours (par ordre chronologique de contribution) :<br>
Yunya Wang, SunJoo Park, Mark Estudillo, Justin Mae, Marina Zavalina, Peeyush Jain, Adrian Pearl, Davida Kollmar, Derek Yen, Tony Xu, Ben Stadnick, Prasanthi Gurumurthy, Amartya Prasad, Dongning Fang, Yuxin Tang, Sahana Upadhya, Micaela Flores, Sheetal Laad, Brina Seidel, Aishwarya Rajan, Jiuhong Xiao, Trieu Trinh, Elliot Silva, Calliea Pan, Chris Ick, Soham Tamba, Ziyu Lei, Hengyu Tang, Ashwin Bhola, Nyutian Long, Linfeng Zhang, Poornima Haridas, Yuchi Ge, Anshan He, Shuting Gu, Weiyang Wen, Vaibhav Gupta, Himani Shah, Gowri Addepalli, Lakshmi Addepalli, Guido Petri, Haoyue Ping, Chinmay Singhal, Divya Juneja, Leyi Zhu, Siqi Wang, Tao Wang, Anqi Zhang, Shiqing Li, Chenqin Yang, Yakun Wang, Jimin Tan, Jiayao Liu, Jialing Xu, Zhengyang Bian, Christina Dominguez, Zhengyuan Ding, Biao Huang, Lin Jiang, Nhung Le, Karanbir Singh Chahal，Meiyi He, Alexander Gao, Weicheng Zhu, Ravi Choudhary，B V Nithish Addepalli, Syed Rahman，Jiayi Du, Xinmeng Li, Atul Gandhi, Li Jiang, Xiao Li, Vishwaesh Rajiv, Wenjun Qu, Xulai Jiang, Shuya Zhao, Henry Steinitz, Rutvi Malaviya, Aathira Manoj, Richard Pang, Aja Klevs, Hsin-Rung Chou, Mrinal Jain, Kelly Sooch, Anthony Tse, Arushi Himatsingka, Eric Kosgey, Bofei Zhang, Andrew Hopen, Maxwell Goldstein, Zeping Zhan, William Huang, Kunal Gadkar, Gaomin Wu, Lin Ye, Aniket Bhatnagar, Dhruv Goyal, Cole Smith, Nikhil Supekar, Zhonghui Hu, Yuqing Wang, Alfred Ajay Aureate Rajakumar, Param Shah, Muyang Jin, Jianzhi Li, Jing Qian, Zeming Lin, Haochen Wang, Eunkyung An, Ying Jin, Ningyuan Huang, Charles Brillo-Sonnino, Shizhan Gong, Natalie Frank, Yunan Hu, Anuj Menta, Dipika Rajesh, Vikas Patidar, Mohith Damarapati, Jiayu Qiu, Yuhong Zhu, Lyuang Fu, Ian Leefmans, Trevor Mitchell, Andrii Dobroshynskyi, Shreyas Chandrakaladharan, Ben Wolfson, Francesca Guiso, Annika Brundyn, Noah Kasmanoff, Luke Martin, Bilal Munawar, Alexander Bienstock, Can Cui, Shaoling Chen, Neil Menghani, Tejaishwarya Gagadam, Joshua Meisel, Jatin Khilnani, Go Inoue, Muhammad Osama Khan, Muhammad Shujaat Mirza, Muhammad Muneeb Afzal, Junrong Zha, Muge Chen, Rishabh Yadav, Zhuocheng Xu, Yada Pruksachatkun, Ananya Harsh Jha, Joseph Morag, Dan Jefferys-White, Brian Kelly, Karl Otness, Xiaoyi Zhang, Shreyas Chandrakaladharan, Chady Raach, Yilang Hao, Binfeng Xu, Ebrahim Rasromani, Mars Wei-Lun Huang, Anu-Ujin Gerelt-Od, Sunidhi Gupta, Bichen Kou, Binfeng Xu, Rajashekar Vasantha, Wenhao Li, Vidit Bhargava, Monika Dagar, Nandhitha Raghuram, Xinyi Zhao, Vasudev Awatramani, Sumit Mamtani, Srishti Bhargava, Jude Naveen Raj Ilango, Duc Anh Phi, Krishna Karthik Reddy Jonnala, Rahul Ahuja, jingshuai jiang, Cal Peyser, Kevin Chang, Gyanesh Gupta, Abed Qaddoumi, Fanzeng Xia, Rohith Mukku, Angela Teng, Joanna Jin, Yang Zhou, Daniel Yao et Sai Charitha Akula.
</p>
